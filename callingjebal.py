# callingjebal.py (ìˆ˜ì •ëœ ì½”ë“œ)

import streamlit as st
import base64
import numpy as np
import io
import librosa
from tflite_runtime.interpreter import Interpreter # tflite-runtime ì‚¬ìš© ê°€ì •

# TFLite ëª¨ë¸ ë° ë¼ë²¨ ë¡œë”© í•¨ìˆ˜ (ì´ì „ì— ì •ì˜í–ˆë˜ í•¨ìˆ˜ ì‚¬ìš©)
@st.cache_resource
def load_tflite_model(model_path, labels_path):
    # ... TFLite Interpreter ë¡œë“œ ë° ë¼ë²¨ ë¡œë“œ ...
    interpreter = Interpreter(model_path=model_path)
    interpreter.allocate_tensors()
    # ... ë¼ë²¨ ë¡œë“œ ë¡œì§ ...
    return interpreter, labels

# HTML íŒŒì¼ì„ ì½ì–´ Streamlit ì»´í¬ë„ŒíŠ¸ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜
def record_audio_component(html_file_path):
    with open(html_file_path, 'r', encoding='utf-8') as f:
        html_code = f.read()
    
    # st.components.v1.htmlì„ ì‚¬ìš©í•˜ì—¬ HTML ì½”ë“œ ì‚½ì…
    # ì´ í•¨ìˆ˜ê°€ JavaScriptë¡œë¶€í„° ë°˜í™˜ëœ ê°’ (Base64 ì˜¤ë””ì˜¤)ì„ ë°›ìŠµë‹ˆë‹¤.
    # heightëŠ” ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ í¬ê¸°ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš”.
    audio_data_base64 = st.components.v1.html(
        html_code, 
        height=150, 
        scrolling=False
    )
    return audio_data_base64

# ë©”ì¸ í•¨ìˆ˜
def main():
    st.title("ğŸ¤ HTML ì„ë² ë”© ì˜¤ë””ì˜¤ ë¶„ë¥˜ê¸°")
    
    # 1. ëª¨ë¸ ë¡œë“œ
    interpreter, labels = load_tflite_model("soundclassifier_with_metadata.tflite", "labels.txt")
    st.sidebar.success("âœ… TFLite ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 2. HTML ì»´í¬ë„ŒíŠ¸ ì‚½ì… ë° Base64 ë°ì´í„° ë°›ê¸°
    # HTML íŒŒì¼ ê²½ë¡œê°€ GitHub ì €ì¥ì†Œ ë£¨íŠ¸ì— ìˆë‹¤ê³  ê°€ì •
    base64_audio = record_audio_component("microphone_recorder.html") 

    if base64_audio:
        st.info("ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ. ë¶„ë¥˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        # 3. Base64 ë°ì´í„°ë¥¼ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ë³€í™˜
        audio_bytes = base64.b64decode(base64_audio)
        audio_stream = io.BytesIO(audio_bytes)
        
        # í™•ì¸ìš© ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ (wav í¬ë§· ê°€ì •)
        st.audio(audio_bytes, format='audio/wav')

        # 4. ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° ì¶”ë¡  (Librosa ë° TFLite ì‚¬ìš©)
        with st.spinner('ëª¨ë¸ ì¶”ë¡  ì¤‘...'):
            try:
                # Librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ ë° ë¦¬ìƒ˜í”Œë§ (ëª¨ë¸ í•™ìŠµ ì‹œ SR ì‚¬ìš©)
                audio_data, sr = librosa.load(audio_stream, sr=16000) 
                
                # run_inference í•¨ìˆ˜ í˜¸ì¶œ (ì´ ë¡œì§ì€ ì‚¬ìš©ìê°€ êµ¬í˜„í•´ì•¼ í•¨)
                # ì˜ˆ: run_inference(interpreter, audio_data, sr, labels)
                
                # ì„ì‹œ ê²°ê³¼ ì¶œë ¥
                predicted_label = labels[np.random.randint(0, len(labels))]
                st.success(f"ë¶„ë¥˜ ê²°ê³¼: **{predicted_label}**")
                
            except Exception as e:
                st.error(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.warning("ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ë¡œì§(ë¦¬ìƒ˜í”Œë§, ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±)ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    # st.set_page_config(layout="wide") # ì „ì²´ í™”ë©´ ì„¤ì • (ì„ íƒ ì‚¬í•­)
    main()
